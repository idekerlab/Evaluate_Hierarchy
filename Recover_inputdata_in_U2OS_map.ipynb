{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for runing batch hidef community detection with input \n",
    "\n",
    "## Use the input data to evaluate the coverage of the output MuSIC map \n",
    "\n",
    "Goals:\n",
    "* run the community detection of input 1.) DenseNet embedding 2.) Node2Vec embedding  3.)Original Bioplex network \n",
    "    * with the same parameter combination and with bad hierarchies removed \n",
    "\n",
    "* Add HPA annotated compartments/locations for geneset enrichment analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from cellmaps_utils.music_utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import hypergeom, mannwhitneyu, ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hypergeo_enrichr(ont_ts, hierarchygenes, ref_file, fdr_thre=0.01, ji_thre = 0, minCompSize=4):  \n",
    "    '''\n",
    "    ont_ts: the result hierarchy from the community detection \n",
    "    hierarchy genes: total number of genes in the root of the hierarchy \n",
    "    ref_file: the reference cellular component/protein complexes table \n",
    "    fdr_thre: the fdr cutoff to be collected in the enriched terms (default = 0.01)\n",
    "    ji_thre: the threshold for Jaccard Idex (default = 0, will set the threshold in the organization step)\n",
    "    minCompSize: the smallest component size to be considered for the enrichment (default = 4)\n",
    "    '''\n",
    "    \n",
    "    M = len(hierarchygenes)\n",
    "    \n",
    "    track = 0\n",
    "    ref_df = pd.DataFrame(index=ont_ts.index, columns=ref_file.index, dtype=float)\n",
    "    ji_df = pd.DataFrame(index=ont_ts.index, columns=ref_file.index, dtype=float)\n",
    "    genecount_df = pd.DataFrame(index=ont_ts.index, columns=ref_file.index, dtype=float)\n",
    "    for ont_comp, ont_row in tqdm(ont_ts.iterrows(), total=ont_ts.shape[0]):\n",
    "        track += 1\n",
    "        ont_comp_genes = ont_row['genes'].split(' ')\n",
    "        ont_comp_genes = [x for x in ont_comp_genes if len(x) > 1] #in case theres a weird comma\n",
    "        n = ont_row['tsize']\n",
    "        for comp, row in ref_file.iterrows():\n",
    "            comp_genes = row['genes'].split(' ')\n",
    "            comp_genes = [x for x in comp_genes if len(x) > 1] #in case theres a weird comma\n",
    "            N = len(set(comp_genes).intersection(set(hierarchygenes)))\n",
    "            x = len(set(ont_comp_genes).intersection(set(comp_genes)))\n",
    "            ref_df.at[ont_comp, comp] = hypergeom.sf(x - 1, M, n, N) # calculare the hypergeometric distribution \n",
    "            ji_df.at[ont_comp, comp] = jaccard(set(ont_comp_genes), set(comp_genes)) # calculate the jaccard score\n",
    "            genecount_df.at[ont_comp, comp] = x\n",
    "    fdr = multipletests(ref_df.values.flatten(), method='fdr_bh')[1]\n",
    "    fdr_df = pd.DataFrame(fdr.reshape(ref_df.shape), index=ref_df.index, columns=ref_df.columns, dtype=float)\n",
    "    for comp, row in fdr_df.iterrows():\n",
    "        ont_ts.at[comp, 'enriched'] = 0\n",
    "        ont_ts.at[comp, 'terms'] = \"\"\n",
    "        ont_ts.at[comp, 'gene_counts'] = \"\"\n",
    "        ont_ts.at[comp, 'adjPvalue'] = \"\"\n",
    "        ont_ts.at[comp, 'ji_indexes'] = \"\"\n",
    "\n",
    "        tmp = row[row <= fdr_thre]\n",
    "        \n",
    "        gene_counts = []\n",
    "        terms = []\n",
    "        ji = []\n",
    "        pvalues = []\n",
    "        for term in tmp.index:\n",
    "            if ji_df.at[comp, term] >= ji_thre:\n",
    "                gene_counts.append(genecount_df.at[comp, term])\n",
    "                terms.append(term)\n",
    "                ji.append(ji_df.at[comp,term])\n",
    "                pvalues.append(tmp[term])\n",
    "        tmp_df = pd.DataFrame({'gene':gene_counts,'ji': ji, 'terms': terms, 'pvalue': pvalues})\n",
    "        tmp_df.sort_values(ascending=False, by='ji', inplace=True)\n",
    "        ont_ts.at[comp, 'enriched'] = len(terms)\n",
    "        ont_ts.at[comp, 'terms'] = \"; \".join(tmp_df['terms'])\n",
    "        ont_ts.at[comp, 'gene_counts'] =  \"; \".join(tmp_df['gene'].astype(str))\n",
    "        ont_ts.at[comp, 'adjPvalue'] =  \"; \".join(tmp_df['pvalue'].astype(str))\n",
    "        ont_ts.at[comp, 'ji_indexes'] =  \"; \".join(tmp_df['ji'].astype(str))\n",
    "\n",
    "    for comp in ont_ts.index:\n",
    "        enrich_terms = ji_df.columns[ji_df.loc[comp] == 1].tolist()\n",
    "        for term in enrich_terms:\n",
    "            ont_ts.at[comp, 'enriched'] = ont_ts.at[comp, 'enriched'] + 1\n",
    "            ont_ts.at[comp, 'terms'] = term + \"; \" + ont_ts.at[comp, 'terms']\n",
    "            ont_ts.at[comp, 'ji_indexes'] = str(ji_df.at[comp, term]) + \"; \" + ont_ts.at[comp, 'ji_indexes'] \n",
    "            ont_ts.at[comp, 'adjPvalue'] = str(fdr_df.at[comp, term]) + \"; \" + ont_ts.at[comp, 'adjPvalue']\n",
    "            ont_ts.at[comp, 'gene_counts'] = str(genecount_df.at[comp, term]) + \"; \" + ont_ts.at[comp, 'gene_counts']\n",
    "    print(len(ont_ts))\n",
    "    print('... finished running geneset enrichment')\n",
    "    return ont_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Genes in different HPA locations\n",
    "import json \n",
    "with open(\"/cellar/users/mhu/MuSIC/Resources/u2os_loc.txt\", \"r\") as f:\n",
    "    geneloc =json.loads(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loc_df=pd.DataFrame(geneloc.keys(), columns = ['Locations'])\n",
    "loc_df['genes'] = [x for x in geneloc.values()]\n",
    "loc_df['tsize'] = loc_df.genes.apply(lambda x: len(x))\n",
    "loc_df['genes'] = loc_df.genes.apply(lambda x: ' '.join(x))\n",
    "# loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of hierarchy genes = 5127\n"
     ]
    }
   ],
   "source": [
    "# hidefdir = '/cellar/users/mhu/MuSIC/U2OS/hidef/MUSE/muse_imgdim_128_ppidim_128_latentd_128_lreg_5_lsuper_10_k_30_euc_True_latent/cutoff_hidef/batch_norm_afterz/'\n",
    "# hier = 'U2OS_5183_MUSE_batch_norm_afterz_euc_sim_percthre_1.chi_5.maxres_60.alg_louvain'\n",
    "minTermsize = 4\n",
    "# f = hidefdir +hier+'.nodes'\n",
    "f = '/cellar/users/mhu/MuSIC/U2OS/hidef/MUSE/muse_imgdim_128_ppidim_128_latentd_128_lreg_5_lsuper_10_k_30_euc_True_latent/cutoff_hidef/batch_norm_afterz/U2OS_5183_MUSE_batch_norm_afterz_cos_sim_percthre_0.5.chi_15.maxres_20.alg_louvain.nodes'\n",
    "df = pd.read_table(f, header=None) ## load the input nodes \n",
    "\n",
    "df.columns = ['term', 'tsize', 'genes', 'stability']\n",
    "root_size = df['tsize'].max()\n",
    "\n",
    "hierarchygenes = df[df['tsize'] == root_size]['genes'].values[0].split(' ')  ## select the root node and collect all genes there (all genes included in the map)\n",
    "print(f'number of hierarchy genes = {len(hierarchygenes)}')\n",
    "\n",
    "node_rm = None\n",
    "if len(df[df['tsize']<minTermsize]) >0:\n",
    "    node_rm = df[df['tsize']<minTermsize]['term']#the node need to be removed\n",
    "    print('{} is smaller than minimum term size, Removed'.format(node_rm))  \n",
    "\n",
    "df = df[(df['tsize'] >= minTermsize) & (df['tsize'] < root_size)]\n",
    "df.set_index('term', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Locations'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3866869/3683040255.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloc_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloc_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminTermsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Locations'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hidef/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hidef/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['Locations'] are in the columns\""
     ]
    }
   ],
   "source": [
    "loc_df = loc_df[loc_df['tsize'] >= minTermsize]\n",
    "loc_df.set_index('Locations', inplace=True)\n",
    "len(loc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:01<00:00, 57.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "... finished running geneset enrichment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsize</th>\n",
       "      <th>genes</th>\n",
       "      <th>stability</th>\n",
       "      <th>enriched</th>\n",
       "      <th>terms</th>\n",
       "      <th>gene_counts</th>\n",
       "      <th>adjPvalue</th>\n",
       "      <th>ji_indexes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cluster1-0</th>\n",
       "      <td>1240</td>\n",
       "      <td>AAGAB AAMDC ABI2 ABL2 ABRAXAS1 ABT1 ACBD6 ACD ...</td>\n",
       "      <td>38</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nucleoplasm; Nuclear speckles; Nuclear bodies</td>\n",
       "      <td>997.0; 180.0; 115.0</td>\n",
       "      <td>1.3555328319096712e-203; 1.9311729502629996e-7...</td>\n",
       "      <td>0.3984812150279776; 0.14139827179890024; 0.087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster1-1</th>\n",
       "      <td>821</td>\n",
       "      <td>AAK1 AAR2 ABCE1 ABCF2 ABHD10 ABTB1 ACSF2 ACTR1...</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cytosol</td>\n",
       "      <td>698.0</td>\n",
       "      <td>9.976665413090394e-213</td>\n",
       "      <td>0.3438423645320197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster1-2</th>\n",
       "      <td>753</td>\n",
       "      <td>AAMP ABCA12 ABCB1 ABCB4 ABCC1 ABI1 ACACA ACADM...</td>\n",
       "      <td>28</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Plasma membrane; Actin filaments; Microtubules...</td>\n",
       "      <td>405.0; 84.0; 69.0; 48.0; 47.0; 46.0; 16.0</td>\n",
       "      <td>9.040350741757043e-225; 6.218168378897997e-52;...</td>\n",
       "      <td>0.41838842975206614; 0.10866752910737387; 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster1-3</th>\n",
       "      <td>659</td>\n",
       "      <td>AACS ABCG1 ABHD17A ABLIM1 ACBD3 ACBD5 ACOX3 AC...</td>\n",
       "      <td>30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Golgi apparatus; Vesicles; Centrosome; Centrio...</td>\n",
       "      <td>242.0; 286.0; 50.0; 21.0; 14.0; 12.0; 11.0; 10.0</td>\n",
       "      <td>7.278332302669722e-166; 1.4015438351119064e-93...</td>\n",
       "      <td>0.33060109289617484; 0.2643253234750462; 0.071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster2-0</th>\n",
       "      <td>626</td>\n",
       "      <td>AAMDC ABI2 ABL2 ABT1 ACBD6 ACTL6A ADAM32 ADK A...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nucleoplasm</td>\n",
       "      <td>608.0</td>\n",
       "      <td>9.425920221317688e-211</td>\n",
       "      <td>0.26701800614844096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster2-43</th>\n",
       "      <td>15</td>\n",
       "      <td>ARFIP1 ARNT BAG1 DNAJB1 DNAJB6 DNAJC13 DPH2 EI...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster3-45</th>\n",
       "      <td>14</td>\n",
       "      <td>ALDH1A3 ANXA8L1 BCL2L2 CBX5 HES1 IMPA2 LGALSL ...</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nucleoplasm</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0037218145216976577</td>\n",
       "      <td>0.005752212389380531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster3-46</th>\n",
       "      <td>11</td>\n",
       "      <td>FNTA GDI1 GDI2 INPP5A MRAS RAP1GDS1 RHOA RRAS ...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster3-47</th>\n",
       "      <td>9</td>\n",
       "      <td>BORCS5 CEP55 FAM120B HOMER1 IFFO2 IL13 PPP4C P...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Plasma membrane</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.004018342287418376</td>\n",
       "      <td>0.009630818619582664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster1-13</th>\n",
       "      <td>5</td>\n",
       "      <td>ISL2 LDB2 LMO4 PTAR1 STK3</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rods &amp; Rings</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6219008717761216e-07</td>\n",
       "      <td>0.3333333333333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tsize                                              genes  \\\n",
       "term                                                                    \n",
       "Cluster1-0    1240  AAGAB AAMDC ABI2 ABL2 ABRAXAS1 ABT1 ACBD6 ACD ...   \n",
       "Cluster1-1     821  AAK1 AAR2 ABCE1 ABCF2 ABHD10 ABTB1 ACSF2 ACTR1...   \n",
       "Cluster1-2     753  AAMP ABCA12 ABCB1 ABCB4 ABCC1 ABI1 ACACA ACADM...   \n",
       "Cluster1-3     659  AACS ABCG1 ABHD17A ABLIM1 ACBD3 ACBD5 ACOX3 AC...   \n",
       "Cluster2-0     626  AAMDC ABI2 ABL2 ABT1 ACBD6 ACTL6A ADAM32 ADK A...   \n",
       "...            ...                                                ...   \n",
       "Cluster2-43     15  ARFIP1 ARNT BAG1 DNAJB1 DNAJB6 DNAJC13 DPH2 EI...   \n",
       "Cluster3-45     14  ALDH1A3 ANXA8L1 BCL2L2 CBX5 HES1 IMPA2 LGALSL ...   \n",
       "Cluster3-46     11  FNTA GDI1 GDI2 INPP5A MRAS RAP1GDS1 RHOA RRAS ...   \n",
       "Cluster3-47      9  BORCS5 CEP55 FAM120B HOMER1 IFFO2 IL13 PPP4C P...   \n",
       "Cluster1-13      5                          ISL2 LDB2 LMO4 PTAR1 STK3   \n",
       "\n",
       "             stability  enriched  \\\n",
       "term                               \n",
       "Cluster1-0          38       3.0   \n",
       "Cluster1-1          68       1.0   \n",
       "Cluster1-2          28       7.0   \n",
       "Cluster1-3          30       8.0   \n",
       "Cluster2-0          57       1.0   \n",
       "...                ...       ...   \n",
       "Cluster2-43         18       0.0   \n",
       "Cluster3-45         26       1.0   \n",
       "Cluster3-46         29       0.0   \n",
       "Cluster3-47         20       1.0   \n",
       "Cluster1-13         35       1.0   \n",
       "\n",
       "                                                         terms  \\\n",
       "term                                                             \n",
       "Cluster1-0       Nucleoplasm; Nuclear speckles; Nuclear bodies   \n",
       "Cluster1-1                                             Cytosol   \n",
       "Cluster1-2   Plasma membrane; Actin filaments; Microtubules...   \n",
       "Cluster1-3   Golgi apparatus; Vesicles; Centrosome; Centrio...   \n",
       "Cluster2-0                                         Nucleoplasm   \n",
       "...                                                        ...   \n",
       "Cluster2-43                                                      \n",
       "Cluster3-45                                        Nucleoplasm   \n",
       "Cluster3-46                                                      \n",
       "Cluster3-47                                    Plasma membrane   \n",
       "Cluster1-13                                       Rods & Rings   \n",
       "\n",
       "                                                  gene_counts  \\\n",
       "term                                                            \n",
       "Cluster1-0                                997.0; 180.0; 115.0   \n",
       "Cluster1-1                                              698.0   \n",
       "Cluster1-2          405.0; 84.0; 69.0; 48.0; 47.0; 46.0; 16.0   \n",
       "Cluster1-3   242.0; 286.0; 50.0; 21.0; 14.0; 12.0; 11.0; 10.0   \n",
       "Cluster2-0                                              608.0   \n",
       "...                                                       ...   \n",
       "Cluster2-43                                                     \n",
       "Cluster3-45                                              13.0   \n",
       "Cluster3-46                                                     \n",
       "Cluster3-47                                               6.0   \n",
       "Cluster1-13                                               3.0   \n",
       "\n",
       "                                                     adjPvalue  \\\n",
       "term                                                             \n",
       "Cluster1-0   1.3555328319096712e-203; 1.9311729502629996e-7...   \n",
       "Cluster1-1                              9.976665413090394e-213   \n",
       "Cluster1-2   9.040350741757043e-225; 6.218168378897997e-52;...   \n",
       "Cluster1-3   7.278332302669722e-166; 1.4015438351119064e-93...   \n",
       "Cluster2-0                              9.425920221317688e-211   \n",
       "...                                                        ...   \n",
       "Cluster2-43                                                      \n",
       "Cluster3-45                              0.0037218145216976577   \n",
       "Cluster3-46                                                      \n",
       "Cluster3-47                               0.004018342287418376   \n",
       "Cluster1-13                             2.6219008717761216e-07   \n",
       "\n",
       "                                                    ji_indexes  \n",
       "term                                                            \n",
       "Cluster1-0   0.3984812150279776; 0.14139827179890024; 0.087...  \n",
       "Cluster1-1                                  0.3438423645320197  \n",
       "Cluster1-2   0.41838842975206614; 0.10866752910737387; 0.08...  \n",
       "Cluster1-3   0.33060109289617484; 0.2643253234750462; 0.071...  \n",
       "Cluster2-0                                 0.26701800614844096  \n",
       "...                                                        ...  \n",
       "Cluster2-43                                                     \n",
       "Cluster3-45                               0.005752212389380531  \n",
       "Cluster3-46                                                     \n",
       "Cluster3-47                               0.009630818619582664  \n",
       "Cluster1-13                                 0.3333333333333333  \n",
       "\n",
       "[108 rows x 8 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = run_hypergeo_enrichr(df, hierarchygenes, loc_df, fdr_thre=0.01, ji_thre = 0, minCompSize=4)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_eval(df, fdr = 0.01, ji = 0.2):\n",
    "        term_term_mapping = []\n",
    "        for index,row in df.iterrows():\n",
    "            pvalues = str(row[f'adjPvalue']).split('; ')\n",
    "            jaccard_indexes = str(row[f'ji_indexes']).split('; ')\n",
    "            hypergeom_terms = str(row[f'terms']).split('; ')\n",
    "            for i in range(len(pvalues) - 1):\n",
    "                term_term_mapping.append((index, pvalues[i], hypergeom_terms[i], jaccard_indexes[i]))\n",
    "\n",
    "        term_term_mapping = pd.DataFrame(term_term_mapping, columns=['term','pval', 'gs_term', 'ji'])\n",
    "        num_enriched = 0\n",
    "        num_sig = 0\n",
    "        taken_gs_terms = []\n",
    "        taken_terms = []\n",
    "\n",
    "        for index,row in term_term_mapping.sort_values(by='ji', ascending=False).iterrows():\n",
    "            if (row['gs_term'] not in taken_gs_terms) & (row['term'] not in taken_terms):\n",
    "                taken_gs_terms.append(row['gs_term'])\n",
    "                taken_terms.append(row['term'])\n",
    "                if float(row['pval']) <= fdr: \n",
    "                    num_enriched += 1\n",
    "                    if (float(row['pval']) <= fdr) & (float(row['ji']) >= ji):\n",
    "                        num_sig +=1\n",
    "        return (num_enriched, num_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich, sig = enrich_eval(test, fdr = 0.01, ji = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 17\n"
     ]
    }
   ],
   "source": [
    "print(enrich, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node2Vec embedding hierarchies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of node2vec file\n",
    "input_dir = \"/cellar/users/mhu/MuSIC/U2OS/MuSIC_MUSE/Data\"\n",
    "n2v = load_obj(f'{input_dir}/U2OS_Bioplex/Node2Vec/dim_1024_p_2_q_1.gname_converted.pkl') #load n2v\n",
    "u2os_genes = np.load('/cellar/users/mhu/MuSIC/U2OS/MuSIC_MUSE/Data/img_x_ppi.5183.genelist.npy', allow_pickle=True)\n",
    "n2v = n2v[n2v.index.isin(u2os_genes)]  ##filtered for u2os genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPAR1</th>\n",
       "      <td>-0.054839</td>\n",
       "      <td>0.014909</td>\n",
       "      <td>-0.007761</td>\n",
       "      <td>-0.083735</td>\n",
       "      <td>-0.098761</td>\n",
       "      <td>0.025309</td>\n",
       "      <td>0.077098</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>-0.013643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088257</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.121568</td>\n",
       "      <td>-0.041672</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>-0.058908</td>\n",
       "      <td>-0.095545</td>\n",
       "      <td>-0.376645</td>\n",
       "      <td>0.122954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLGN</th>\n",
       "      <td>0.060697</td>\n",
       "      <td>-0.051199</td>\n",
       "      <td>0.024367</td>\n",
       "      <td>0.042730</td>\n",
       "      <td>0.117842</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>-0.184327</td>\n",
       "      <td>-0.092943</td>\n",
       "      <td>-0.129151</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113127</td>\n",
       "      <td>0.075175</td>\n",
       "      <td>-0.052046</td>\n",
       "      <td>0.093476</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>-0.200303</td>\n",
       "      <td>-0.008908</td>\n",
       "      <td>-0.080484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VENTX</th>\n",
       "      <td>-0.078559</td>\n",
       "      <td>0.040191</td>\n",
       "      <td>-0.092456</td>\n",
       "      <td>0.050071</td>\n",
       "      <td>-0.024147</td>\n",
       "      <td>-0.158527</td>\n",
       "      <td>-0.075429</td>\n",
       "      <td>0.087791</td>\n",
       "      <td>0.088395</td>\n",
       "      <td>-0.019562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172603</td>\n",
       "      <td>0.058839</td>\n",
       "      <td>0.108716</td>\n",
       "      <td>0.066948</td>\n",
       "      <td>-0.037080</td>\n",
       "      <td>0.030158</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.179473</td>\n",
       "      <td>0.048359</td>\n",
       "      <td>0.143569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREB3L2</th>\n",
       "      <td>-0.044460</td>\n",
       "      <td>-0.105897</td>\n",
       "      <td>0.114275</td>\n",
       "      <td>-0.042723</td>\n",
       "      <td>0.107784</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>-0.069222</td>\n",
       "      <td>-0.072611</td>\n",
       "      <td>-0.010452</td>\n",
       "      <td>-0.075588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015629</td>\n",
       "      <td>-0.048175</td>\n",
       "      <td>-0.021213</td>\n",
       "      <td>0.082217</td>\n",
       "      <td>0.029391</td>\n",
       "      <td>0.070960</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.088688</td>\n",
       "      <td>-0.078115</td>\n",
       "      <td>0.044017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDX28</th>\n",
       "      <td>-0.060962</td>\n",
       "      <td>0.029248</td>\n",
       "      <td>0.028899</td>\n",
       "      <td>-0.030426</td>\n",
       "      <td>0.045338</td>\n",
       "      <td>-0.183735</td>\n",
       "      <td>0.172176</td>\n",
       "      <td>-0.010493</td>\n",
       "      <td>0.065449</td>\n",
       "      <td>-0.112782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012814</td>\n",
       "      <td>-0.064638</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.019405</td>\n",
       "      <td>-0.018207</td>\n",
       "      <td>0.059696</td>\n",
       "      <td>-0.288469</td>\n",
       "      <td>0.088330</td>\n",
       "      <td>-0.101100</td>\n",
       "      <td>0.181681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDR12</th>\n",
       "      <td>-0.099054</td>\n",
       "      <td>0.138871</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>-0.064386</td>\n",
       "      <td>-0.005894</td>\n",
       "      <td>0.072527</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>0.099544</td>\n",
       "      <td>0.018665</td>\n",
       "      <td>-0.050754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101691</td>\n",
       "      <td>-0.114091</td>\n",
       "      <td>-0.051232</td>\n",
       "      <td>0.176599</td>\n",
       "      <td>0.050801</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>-0.129829</td>\n",
       "      <td>-0.245629</td>\n",
       "      <td>-0.119006</td>\n",
       "      <td>-0.073048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNX30</th>\n",
       "      <td>-0.008233</td>\n",
       "      <td>-0.065134</td>\n",
       "      <td>0.058258</td>\n",
       "      <td>-0.003312</td>\n",
       "      <td>0.038221</td>\n",
       "      <td>0.048632</td>\n",
       "      <td>0.071484</td>\n",
       "      <td>-0.016234</td>\n",
       "      <td>0.080595</td>\n",
       "      <td>0.095440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115892</td>\n",
       "      <td>-0.036842</td>\n",
       "      <td>-0.073982</td>\n",
       "      <td>0.247185</td>\n",
       "      <td>-0.121241</td>\n",
       "      <td>-0.139241</td>\n",
       "      <td>0.031821</td>\n",
       "      <td>-0.018550</td>\n",
       "      <td>-0.206210</td>\n",
       "      <td>0.001165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSD3</th>\n",
       "      <td>0.030550</td>\n",
       "      <td>-0.064015</td>\n",
       "      <td>0.147363</td>\n",
       "      <td>-0.068088</td>\n",
       "      <td>0.110349</td>\n",
       "      <td>0.039857</td>\n",
       "      <td>-0.037257</td>\n",
       "      <td>-0.087123</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>-0.080156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071630</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>-0.006465</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.037602</td>\n",
       "      <td>0.020956</td>\n",
       "      <td>-0.082924</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>-0.074433</td>\n",
       "      <td>0.006205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABCE1</th>\n",
       "      <td>-0.057164</td>\n",
       "      <td>0.100489</td>\n",
       "      <td>-0.002256</td>\n",
       "      <td>0.050893</td>\n",
       "      <td>-0.074641</td>\n",
       "      <td>0.054323</td>\n",
       "      <td>0.062970</td>\n",
       "      <td>0.080352</td>\n",
       "      <td>-0.027381</td>\n",
       "      <td>0.020751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065886</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>0.042905</td>\n",
       "      <td>0.047653</td>\n",
       "      <td>-0.080272</td>\n",
       "      <td>-0.081742</td>\n",
       "      <td>-0.121114</td>\n",
       "      <td>-0.076036</td>\n",
       "      <td>0.056522</td>\n",
       "      <td>-0.015779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APLP1</th>\n",
       "      <td>0.068617</td>\n",
       "      <td>-0.066317</td>\n",
       "      <td>0.021196</td>\n",
       "      <td>0.049172</td>\n",
       "      <td>0.046177</td>\n",
       "      <td>-0.039303</td>\n",
       "      <td>0.061922</td>\n",
       "      <td>-0.012167</td>\n",
       "      <td>0.052795</td>\n",
       "      <td>-0.079699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120872</td>\n",
       "      <td>-0.058255</td>\n",
       "      <td>-0.138374</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>0.091269</td>\n",
       "      <td>-0.134174</td>\n",
       "      <td>-0.069471</td>\n",
       "      <td>0.075219</td>\n",
       "      <td>-0.197472</td>\n",
       "      <td>-0.043319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5         6         7     \\\n",
       "LPAR1   -0.054839  0.014909 -0.007761 -0.083735 -0.098761  0.025309  0.077098   \n",
       "CLGN     0.060697 -0.051199  0.024367  0.042730  0.117842  0.295316 -0.184327   \n",
       "VENTX   -0.078559  0.040191 -0.092456  0.050071 -0.024147 -0.158527 -0.075429   \n",
       "CREB3L2 -0.044460 -0.105897  0.114275 -0.042723  0.107784  0.003660 -0.069222   \n",
       "DDX28   -0.060962  0.029248  0.028899 -0.030426  0.045338 -0.183735  0.172176   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "WDR12   -0.099054  0.138871  0.029087 -0.064386 -0.005894  0.072527 -0.000873   \n",
       "SNX30   -0.008233 -0.065134  0.058258 -0.003312  0.038221  0.048632  0.071484   \n",
       "PSD3     0.030550 -0.064015  0.147363 -0.068088  0.110349  0.039857 -0.037257   \n",
       "ABCE1   -0.057164  0.100489 -0.002256  0.050893 -0.074641  0.054323  0.062970   \n",
       "APLP1    0.068617 -0.066317  0.021196  0.049172  0.046177 -0.039303  0.061922   \n",
       "\n",
       "             8         9         10    ...      1015      1016      1017  \\\n",
       "LPAR1    0.027188  0.012957 -0.013643  ... -0.088257  0.001368  0.028800   \n",
       "CLGN    -0.092943 -0.129151  0.004835  ...  0.113127  0.075175 -0.052046   \n",
       "VENTX    0.087791  0.088395 -0.019562  ... -0.172603  0.058839  0.108716   \n",
       "CREB3L2 -0.072611 -0.010452 -0.075588  ... -0.015629 -0.048175 -0.021213   \n",
       "DDX28   -0.010493  0.065449 -0.112782  ... -0.012814 -0.064638 -0.037636   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "WDR12    0.099544  0.018665 -0.050754  ...  0.101691 -0.114091 -0.051232   \n",
       "SNX30   -0.016234  0.080595  0.095440  ... -0.115892 -0.036842 -0.073982   \n",
       "PSD3    -0.087123  0.041750 -0.080156  ... -0.071630  0.014225 -0.006465   \n",
       "ABCE1    0.080352 -0.027381  0.020751  ...  0.065886  0.030333  0.042905   \n",
       "APLP1   -0.012167  0.052795 -0.079699  ... -0.120872 -0.058255 -0.138374   \n",
       "\n",
       "             1018      1019      1020      1021      1022      1023      1024  \n",
       "LPAR1    0.121568 -0.041672 -0.010725 -0.058908 -0.095545 -0.376645  0.122954  \n",
       "CLGN     0.093476  0.021562  0.022667 -0.001427 -0.200303 -0.008908 -0.080484  \n",
       "VENTX    0.066948 -0.037080  0.030158  0.019971  0.179473  0.048359  0.143569  \n",
       "CREB3L2  0.082217  0.029391  0.070960  0.007344  0.088688 -0.078115  0.044017  \n",
       "DDX28   -0.019405 -0.018207  0.059696 -0.288469  0.088330 -0.101100  0.181681  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "WDR12    0.176599  0.050801  0.012665 -0.129829 -0.245629 -0.119006 -0.073048  \n",
       "SNX30    0.247185 -0.121241 -0.139241  0.031821 -0.018550 -0.206210  0.001165  \n",
       "PSD3     0.013971  0.037602  0.020956 -0.082924  0.013400 -0.074433  0.006205  \n",
       "ABCE1    0.047653 -0.080272 -0.081742 -0.121114 -0.076036  0.056522 -0.015779  \n",
       "APLP1    0.090794  0.091269 -0.134174 -0.069471  0.075219 -0.197472 -0.043319  \n",
       "\n",
       "[5183 rows x 1024 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellmaps_hierarchyeval.hidef_input_cutoff_utils import *\n",
    "savedir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Evaluate_Hierarchy/reference_file/Input'\n",
    "prefix = 'N2V_dim_1024_p_2_q_1.gname_converted'\n",
    "\n",
    "\n",
    "for dist in ['euc_sim', 'cos_sim']:\n",
    "    make_sim_matrix(n2v,savedir, prefix, sim_type = dist)\n",
    "    mat_name = f'{savedir}/{prefix}.{dist}.scaled.pkl'\n",
    "    # print(mat_name)\n",
    "    pair = mat_to_pairs(mat_name, sort = False)\n",
    "    pair_sort = mat_to_pairs(mat_name)\n",
    "\n",
    "    pair.to_csv('{}/{}_{}.ddot'.format(savedir, prefix, dist), sep='\\t', header=False, index=False)\n",
    "    pair_sort.to_csv('{}/{}_{}_sort.ddot'.format(savedir,prefix, dist), sep='\\t', header=False, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Number of files generated: 12\n"
     ]
    }
   ],
   "source": [
    "## create cutoff files \n",
    "\n",
    "cutoffs = [0.2, 0.5, 1, 2, 5, 10]\n",
    "\n",
    "label = 'U2OS_5183_N2V_d_1024'\n",
    "workdir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Input/'\n",
    "savedir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Evaluate_Hierarchy/reference_file/Input'\n",
    "prefix = 'N2V_dim_1024_p_2_q_1.gname_converted'\n",
    "\n",
    "if not os.path.exists(workdir +'N2V/cutoff_hidef'):\n",
    "    os.makedirs(workdir +'N2V/cutoff_hidef')\n",
    "\n",
    "for dist_type in ['euc_sim', 'cos_sim']:\n",
    "    df = pd.read_table('{}/{}_{}_sort.ddot'.format(savedir, prefix, dist_type))\n",
    "    df.columns =['geneA','geneB', 'weight']\n",
    "    total_edges = len(df)\n",
    "    # print(total_edges) #13,429,152\n",
    "    for cutoff in cutoffs:\n",
    "        keep = math.ceil((cutoff/100)*total_edges)\n",
    "            # print(keep) \n",
    "        df_cutoff = df.iloc[0:keep]\n",
    "        df_cutoff.to_csv('{}/N2V/cutoff_hidef/{}_{}_percthre_{}.tsv'.format(workdir,label, dist_type, cutoff),sep='\\t', index=False, header=False)\n",
    "\n",
    "print('Done')    \n",
    "print(f\"Number of files generated: {len(glob('{}/N2V/cutoff_hidef/*.tsv'.format(workdir)))}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of jobs : 148\n",
      "number of jobs : 179\n"
     ]
    }
   ],
   "source": [
    "# ## Create the params file to run hidef \n",
    "\n",
    "label = 'U2OS_5183_N2V_d_1024'\n",
    "workdir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Input/N2V'\n",
    "params = []\n",
    "stabilities = [5, 10, 15]\n",
    "resolutions = [20, 40, 60]\n",
    "algs = ['louvain', 'leiden']\n",
    "cutoff_files = glob('{}/cutoff_hidef/*.tsv'.format(workdir))\n",
    "\n",
    "## load the removed list \n",
    "with open('/cellar/users/mhu/MuSIC/U2OS/hidef/MUSE/muse_imgdim_128_ppidim_128_latentd_128_lreg_5_lsuper_10_k_30_euc_True_latent/cutoff_hidef/batch_norm_afterz/removed_hierarchy_list.txt', \"r\") as f:\n",
    "    removed = f.read().split('\\t')\n",
    "    removed = [s.replace('U2OS_5183_MUSE_batch_norm_afterz', label) for s in removed]\n",
    "\n",
    "for file in cutoff_files :\n",
    "    for stability in stabilities:\n",
    "        for resolution in resolutions:\n",
    "            for alg in algs: \n",
    "                cutoff_fname = file.rsplit('/',1)[-1][:-4]\n",
    "                g = file\n",
    "                outname = '{}.chi_{}.maxres_{}.alg_{}'.format(cutoff_fname,stability,resolution, alg)\n",
    "                if outname in removed:## load do not consider the bad parameter combinations\n",
    "                    continue\n",
    "                else:\n",
    "                    o = '{}/cutoff_hidef/{}'.format(workdir,outname)\n",
    "                params.append('--g {} --k {} --maxres {} --alg {} --o {}'.format(g,stability,resolution, alg, o))\n",
    "print(f'number of jobs : {len(params)}')\n",
    "\n",
    "## this loop creates the params for running layered network hidef\n",
    "for dist_type in ['euc_sim', 'cos_sim']:\n",
    "    cutoff_files = glob('{}/cutoff_hidef/*{}*.tsv'.format(workdir, dist_type))\n",
    "    input_networks = ' '.join(cutoff_files)\n",
    "    # print(input_networks)\n",
    "    for stability in stabilities:\n",
    "        for resolution in resolutions:\n",
    "            for alg in algs: \n",
    "                g = input_networks\n",
    "                outname = '{}_{}_layered.chi_{}.maxres_{}.alg_{}'.format(label, dist_type,stability,resolution, alg)\n",
    "                if outname in removed:\n",
    "                    continue\n",
    "                else:\n",
    "                    o = '{}/cutoff_hidef/{}'.format(workdir, outname)\n",
    "                params.append('--g {} --k {} --maxres {} --alg {} --o {}'.format(g,stability,resolution, alg, o))\n",
    "print(f'number of jobs : {len(params)}')\n",
    "                \n",
    "with open(f'{workdir}/cutoff_hidef/run_cutoff_hidef_weights.param', 'w') as p:\n",
    "    p.write('\\n'.join(params))\n",
    "\n",
    "\n",
    "if not os.path.exists(f'{workdir}/cutoff_hidef/errfile'):\n",
    "    os.makedirs(f'{workdir}/cutoff_hidef/errfile')\n",
    "    \n",
    "if not os.path.exists(f'{workdir}/cutoff_hidef/outfile'):\n",
    "    os.makedirs(f'{workdir}/cutoff_hidef/outfile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet embedding hierarchies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5183\n"
     ]
    }
   ],
   "source": [
    "# location of node2vec file\n",
    "input_dir = \"/cellar/users/mhu/MuSIC/U2OS/MuSIC_MUSE/Data\"\n",
    "dn = load_obj(f'{input_dir}/image_data/fold_1/10_fold_embedding.pkl').T #load dn\n",
    "# dn\n",
    "u2os_genes = np.load('/cellar/users/mhu/MuSIC/U2OS/MuSIC_MUSE/Data/img_x_ppi.5183.genelist.npy', allow_pickle=True)\n",
    "dn = dn[dn.index.isin(u2os_genes)]  ##filtered for u2os genes\n",
    "print(len(dn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Evaluate_Hierarchy/reference_file/Input'\n",
    "prefix = 'DN_d_1024_fold_1'\n",
    "\n",
    "## create the pair-wise similarity list \n",
    "for dist in ['euc_sim', 'cos_sim']:\n",
    "    #create the similarity matrix\n",
    "    make_sim_matrix(dn,savedir, prefix, sim_type = dist)\n",
    "    mat_name = f'{savedir}/{prefix}.{dist}.scaled.pkl'\n",
    "    # print(mat_name)\n",
    "    #convert similarity matrix to pairwise similarity table (save the file sort by weight or not)\n",
    "    pair = mat_to_pairs(mat_name, sort = False)\n",
    "    pair_sort = mat_to_pairs(mat_name)\n",
    "\n",
    "    pair.to_csv('{}/{}_{}.ddot'.format(savedir, prefix, dist), sep='\\t', header=False, index=False)\n",
    "    pair_sort.to_csv('{}/{}_{}_sort.ddot'.format(savedir,prefix, dist), sep='\\t', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Number of files generated: 12\n"
     ]
    }
   ],
   "source": [
    "## create cutoff files \n",
    "\n",
    "cutoffs = [0.2, 0.5, 1, 2, 5, 10]\n",
    "\n",
    "label = 'U2OS_5183_DN_d_1024_fold_1'\n",
    "workdir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Input/'\n",
    "savedir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Evaluate_Hierarchy/reference_file/Input'\n",
    "prefix = 'DN_d_1024_fold_1'\n",
    "\n",
    "if not os.path.exists(workdir +'DenseNet/cutoff_hidef'):\n",
    "    os.makedirs(workdir +'DenseNet/cutoff_hidef')\n",
    "\n",
    "for dist_type in ['euc_sim', 'cos_sim']:\n",
    "    df = pd.read_table('{}/{}_{}_sort.ddot'.format(savedir, prefix, dist_type))\n",
    "    df.columns =['geneA','geneB', 'weight']\n",
    "    total_edges = len(df)\n",
    "    # print(total_edges) #13,429,152\n",
    "    for cutoff in cutoffs:\n",
    "        keep = math.ceil((cutoff/100)*total_edges)\n",
    "            # print(keep) \n",
    "        df_cutoff = df.iloc[0:keep]\n",
    "        df_cutoff.to_csv('{}/DenseNet/cutoff_hidef/{}_{}_percthre_{}.tsv'.format(workdir,label, dist_type, cutoff),sep='\\t', index=False, header=False)\n",
    "\n",
    "print('Done')    \n",
    "print(f\"Number of files generated: {len(glob('{}/DenseNet/cutoff_hidef/*.tsv'.format(workdir)))}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of jobs : 148\n",
      "number of jobs : 179\n"
     ]
    }
   ],
   "source": [
    "# ## Create the params file to run hidef \n",
    "\n",
    "label = 'U2OS_5183_DN_d_1024_fold_1'\n",
    "workdir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Input/DenseNet'\n",
    "params = []\n",
    "stabilities = [5, 10, 15]\n",
    "resolutions = [20, 40, 60]\n",
    "algs = ['louvain', 'leiden']\n",
    "cutoff_files = glob('{}/cutoff_hidef/*.tsv'.format(workdir))\n",
    "## load the removed list \n",
    "with open('/cellar/users/mhu/MuSIC/U2OS/hidef/MUSE/muse_imgdim_128_ppidim_128_latentd_128_lreg_5_lsuper_10_k_30_euc_True_latent/cutoff_hidef/batch_norm_afterz/removed_hierarchy_list.txt', \"r\") as f:\n",
    "    removed = f.read().split('\\t')\n",
    "    removed = [s.replace('U2OS_5183_MUSE_batch_norm_afterz', label) for s in removed]\n",
    "\n",
    "for file in cutoff_files :\n",
    "    for stability in stabilities:\n",
    "        for resolution in resolutions:\n",
    "            for alg in algs: \n",
    "                cutoff_fname = file.rsplit('/',1)[-1][:-4]\n",
    "                g = file\n",
    "                outname = '{}.chi_{}.maxres_{}.alg_{}'.format(cutoff_fname,stability,resolution, alg)\n",
    "                if outname in removed:## Do not consider the bad combinations\n",
    "                    continue\n",
    "                else:\n",
    "                    o = '{}/cutoff_hidef/{}'.format(workdir,outname)\n",
    "                params.append('--g {} --k {} --maxres {} --alg {} --o {}'.format(g,stability,resolution, alg, o))\n",
    "print(f'number of jobs : {len(params)}')\n",
    "\n",
    "\n",
    "## this loop creates the params for running layered network hidef\n",
    "for dist_type in ['euc_sim', 'cos_sim']:\n",
    "    cutoff_files = glob('{}/cutoff_hidef/*{}*.tsv'.format(workdir, dist_type))\n",
    "    input_networks = ' '.join(cutoff_files)\n",
    "    # print(input_networks)\n",
    "    for stability in stabilities:\n",
    "        for resolution in resolutions:\n",
    "            for alg in algs: \n",
    "                g = input_networks\n",
    "                outname = '{}_{}_layered.chi_{}.maxres_{}.alg_{}'.format(label, dist_type,stability,resolution, alg)\n",
    "                if outname in removed:\n",
    "                    continue\n",
    "                else:\n",
    "                    o = '{}/cutoff_hidef/{}'.format(workdir, outname)\n",
    "                params.append('--g {} --k {} --maxres {} --alg {} --o {}'.format(g,stability,resolution, alg, o))\n",
    "print(f'number of jobs : {len(params)}')\n",
    "                \n",
    "with open(f'{workdir}/cutoff_hidef/run_cutoff_hidef_weights.param', 'w') as p:\n",
    "    p.write('\\n'.join(params))\n",
    "\n",
    "\n",
    "if not os.path.exists(f'{workdir}/cutoff_hidef/errfile'):\n",
    "    os.makedirs(f'{workdir}/cutoff_hidef/errfile')\n",
    "    \n",
    "if not os.path.exists(f'{workdir}/cutoff_hidef/outfile'):\n",
    "    os.makedirs(f'{workdir}/cutoff_hidef/outfile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioPlex Hierarchy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of jobs : 18\n"
     ]
    }
   ],
   "source": [
    "# location of node2vec file\n",
    "input_dir = \"/cellar/users/mhu/MuSIC/U2OS/MuSIC_MUSE/Data\"\n",
    "bioplex = f'{input_dir}/U2OS_Bioplex/bioplex_edges_x_u2os.txt' #load u2os bioplex\n",
    "\n",
    "workdir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Input/Bioplex'\n",
    "if not os.path.exists(workdir +'/cutoff_hidef'):\n",
    "    os.makedirs(workdir +'/cutoff_hidef')\n",
    "\n",
    "params = []\n",
    "stabilities = [5, 10, 15]\n",
    "resolutions = [20, 40, 60]\n",
    "algs = ['louvain', 'leiden']\n",
    "\n",
    "for stability in stabilities:\n",
    "    for resolution in resolutions:\n",
    "        for alg in algs: \n",
    "            g = bioplex\n",
    "            outname = 'U2OS_5183_bioplex.chi_{}.maxres_{}.alg_{}'.format(stability,resolution, alg)\n",
    "            o = '{}/cutoff_hidef/{}'.format(workdir,outname)\n",
    "            params.append('--g {} --k {} --maxres {} --alg {} --o {}'.format(g,stability,resolution, alg, o))\n",
    "print(f'number of jobs : {len(params)}')\n",
    "\n",
    "with open(f'{workdir}/cutoff_hidef/run_cutoff_hidef_weights.param', 'w') as p:\n",
    "    p.write('\\n'.join(params))\n",
    "\n",
    "\n",
    "if not os.path.exists(f'{workdir}/cutoff_hidef/errfile'):\n",
    "    os.makedirs(f'{workdir}/cutoff_hidef/errfile')\n",
    "    \n",
    "if not os.path.exists(f'{workdir}/cutoff_hidef/outfile'):\n",
    "    os.makedirs(f'{workdir}/cutoff_hidef/outfile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DN'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workdir = '/cellar/users/mhu/MuSIC/U2OS/hidef/Input/DenseNet/cutoff_hidef/'\n",
    "\n",
    "n2v_files = glob(f'{workdir}*nodes')\n",
    "n2v_files[0].rsplit('/',1)[-1].rsplit('_')[2].rsplit('.')[0]\n",
    "# n2v_files[0].rsplit('/',1)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for run enrichr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "73\n",
      "179\n",
      "179 179 18\n",
      "number of jobs : 179\n"
     ]
    }
   ],
   "source": [
    "## Create the param file \n",
    "label = 'U2OS_5183_MUSE_batch_norm_afterz'\n",
    "hidefdir = '/cellar/users/mhu/MuSIC/U2OS/hidef/MUSE/muse_imgdim_128_ppidim_128_latentd_128_lreg_5_lsuper_10_k_30_euc_True_latent/cutoff_hidef/batch_norm_afterz/'\n",
    "refdir ='/cellar/users/mhu/MuSIC/U2OS/hidef/Input'\n",
    "\n",
    "hidef_files = glob('{}*nodes'.format(hidefdir))\n",
    "print(len(hidef_files))\n",
    "with open('{}removed_hierarchy_list.txt'.format(hidefdir), \"r\") as f:\n",
    "    removed = f.read().split('\\t')\n",
    "    removed = [hidefdir+i+'.nodes' for i in removed]\n",
    "print(len(removed))\n",
    "hidef_analyze= set(hidef_files) - set(removed)\n",
    "print(len(hidef_analyze))\n",
    "\n",
    "## obtain all the nodes files from N2V, DN and bioplex\n",
    "N2V_files = glob(f'{refdir}/N2V/cutoff_hidef/*nodes')\n",
    "DN_files = glob(f'{refdir}/DenseNet/cutoff_hidef/*nodes')\n",
    "bioplex_files = glob(f'{refdir}/Bioplex/cutoff_hidef/*nodes')\n",
    "print(len(N2V_files), len(DN_files), len(bioplex_files))\n",
    "\n",
    "params = []\n",
    "for hidef_file in hidef_analyze:\n",
    "    reflist = []\n",
    "    hier = hidef_file.rsplit('/',1)[-1]\n",
    "    # print(hier)\n",
    "    param = hier.replace('U2OS_5183_MUSE_batch_norm_afterz_','') # remove the prefix label \n",
    "    reflist += [x for x in DN_files if param in x]+[x for x in N2V_files if param in x] # find the DN and N2V hierarchy with the same param settings \n",
    "    hidef_param = '.'.join(param.rsplit('.')[-4:]) # only keep the part with chi, maxres and alg \n",
    "    # print(hidef_param)\n",
    "    reflist += [x for x in bioplex_files if hidef_param in x]\n",
    "    assert (len(reflist) == 3), f'missing refs for {hier}'\n",
    "    # print(len(reflist))\n",
    "    reflist = ' '.join(reflist) # when pass into args, it does not accept comma\n",
    "    \n",
    "    prefix = hidef_file[:-6]\n",
    "    \n",
    "    params.append('--outprefix {} --infname {}  --refhier {}'.format(prefix, hidef_file, reflist))\n",
    "    \n",
    "print(f'number of jobs : {len(params)}')\n",
    "\n",
    "with open(f'/cellar/users/mhu/MuSIC/U2OS/hidef//run_enrichr_input.param', 'w') as p:\n",
    "    p.write('\\n'.join(params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test run\n",
    "Confirm the program is working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of hierarchy genes = 5127\n",
      "Number of hierarchy nodes: 108\n",
      "type of ref is DN\n",
      "number of hierarchy genes = 4644\n",
      "Number of hierarchy nodes: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:03<00:00, 30.73it/s]\n",
      "  1%|          | 1/108 [00:00<00:14,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 108\n",
      "... finished running geneset enrichment\n",
      "type of ref is N2V\n",
      "number of hierarchy genes = 4871\n",
      "Number of hierarchy nodes: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:08<00:00, 13.14it/s]\n",
      "  2%|▏         | 2/108 [00:00<00:08, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 108\n",
      "... finished running geneset enrichment\n",
      "type of ref is bioplex\n",
      "number of hierarchy genes = 4757\n",
      "Number of hierarchy nodes: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:05<00:00, 19.05it/s]\n",
      "  4%|▎         | 4/108 [00:00<00:02, 39.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 108\n",
      "... finished running geneset enrichment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:02<00:00, 52.76it/s]\n",
      "  0%|          | 0/108 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 108\n",
      "... finished running geneset enrichment\n",
      "... finished running enrichment analysis\n",
      "4704\n",
      "... finished loading PPI data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 107/108 [03:09<00:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finished running edge enrichment analysis\n",
      "=== finished analyze_hidef_output ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [03:11<00:00,  1.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python = '/cellar/users/mhu/miniconda3/envs/hidef/bin/python '\n",
    "test_run = f'/cellar/users/mhu/MuSIC/U2OS/hidef/Evaluate_Hierarchy/Input_hierarchy_enrichment_in_MuSIC.py {params[0]}'\n",
    "# python + test_run\n",
    "os.system(python + test_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
